name: Performance
run-name: Performance test against ${{ inputs.BaseURL }} for URN ${{ inputs.URN }}

on:
  push:
    branches:
      - performance-testing

  workflow_dispatch:
    inputs:
      runImport:
        description: "Create and import a cohort (not needed if there are already enough patients)"
        required: true
        type: boolean
        default: false
      runConsent:
        description: "Run consent journey"
        required: true
        type: boolean
        default: true
      runNurse:
        description: "Run the nurse journey"
        required: true
        type: boolean
        default: true
      URN:
        description: "Required: what URN to run the test against."
        required: true
        type: string
      duration:
        description: "Optional (default 3600) Duration of nurse journey test, in seconds. This will include ramp-up."
        required: false
        type: number
        default: 3600
      threads:
        description: "Optional (default 70) Threads to run. Equivalent to the number of nurses using the system."
        required: false
        type: number
        default: 70
      ramp_up:
        description: "Optional (default 900) Ramp-up time in seconds. Threads will be gradually started up over this time."
        required: false
        type: number
        default: 900
      row_count:
        description: "Optional (default 1000) number of rows in the cohort file."
        required: false
        type: number
        default: 1000
      user:
        description: "Optional (default Nurse perftest) user."
        required: true
        type: string
        default: 'nurse.perftest@example.com'
      BaseURL:
        description: "Optional (default qa.mavistesting.com) URL"
        required: true
        type: string
        default: 'qa.mavistesting.com'

jobs:
  check-image-presence:
    name: Check if docker image already exists
    runs-on: ubuntu-latest
    permissions:
      id-token: write
    outputs:
      build-needed: ${{ steps.check-image.outputs.build-needed }}
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: arn:aws:iam::393416225559:role/GitHubAssuranceTestRole
          aws-region: eu-west-2
      - name: Check if image exists
        id: check-image
        run: |
          if aws ecr describe-images --repository-name performancetest --image-ids imageTag=${{ github.sha }} > /dev/null 2>&1; then
            echo "Docker image with given tag already exists"
          else
            echo "Docker image does not exist. Build needed"
            echo "build-needed=true" >> $GITHUB_OUTPUT
          fi
  build-and-push:
    needs: check-image-presence
    if: needs.check-image-presence.outputs.build-needed == 'true'
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: performance-tests/
    permissions:
      id-token: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: arn:aws:iam::393416225559:role/GitHubAssuranceTestRole
          aws-region: eu-west-2
      - name: Cache base jmeter image
        id: jmeter-base
        uses: actions/cache@v4
        env:
          cache-name: cache-jmeter
        with:
          path: ${{ runner.temp }}/jmeter-image.tar
          key: jmeter-image-${{ hashFiles('performance-tests/base.Dockerfile') }}
      - name: Build base jmeter image
        if: steps.jmeter-base.outputs.cache-hit != 'true'
        run: |
          docker build -t base-jmeter-image:latest -f base.Dockerfile .
          docker save -o ${{ runner.temp }}/jmeter-image.tar base-jmeter-image:latest
      - name: Login to ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
      - name: Build and push performancetest docker image
        run: |
          docker load -i ${{ runner.temp }}/jmeter-image.tar
          docker build -t "393416225559.dkr.ecr.eu-west-2.amazonaws.com/performancetest:${{ github.sha }}" .
          docker push "393416225559.dkr.ecr.eu-west-2.amazonaws.com/performancetest:${{ github.sha }}"
  run-performance-test:
    needs: [build-and-push, check-image-presence]
    if: ${{ !cancelled() &&
      (needs.build-and-push.result == 'success' || 
      (needs.check-image-presence.result == 'success' && needs.build-and-push.result == 'skipped')
      ) }}
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: write
    timeout-minutes: 180
    env:
      RESULT_PATH: ${{ inputs.URN }}/${{ github.run_number }}
    steps:
      - uses: actions/checkout@v5
      - name: Set timestamp
        run: echo "timestamp=$(date '+%Y%m%d%H%M%S')" >> $GITHUB_ENV
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: arn:aws:iam::393416225559:role/GitHubAssuranceTestRole
          aws-region: eu-west-2
      - name: Create task definition
        id: create-task-definition
        uses: aws-actions/amazon-ecs-render-task-definition@v1
        with:
          task-definition-family: "assurance-testing-performance-task-definition-template"
          container-name: "performancetest-container"
          image: "393416225559.dkr.ecr.eu-west-2.amazonaws.com/performancetest:${{ github.sha }}"
          environment-variables: |
            RUN_IMPORT=${{ inputs.runImport }}
            RUN_CONSENT=${{ inputs.runConsent }}
            RUN_NURSE=${{ inputs.runNurse }}
            RESULT_PATH=${{ env.RESULT_PATH }}
            URN=${{ inputs.URN }}
            BASE_URL=${{ inputs.BaseURL }}
            USER=${{ inputs.user }}
            DURATION=${{ inputs.duration }}
            THREADS=${{ inputs.threads }}
            RAMP_UP=${{ inputs.ramp_up }}
            ROW_COUNT=${{ inputs.row_count }}
          secrets: |
            AUTH_TOKEN=arn:aws:secretsmanager:eu-west-2:393416225559:secret:performancetest/auth-token
      - name: Register task definition
        id: register-task-definition
        run: |
          file_path="assurance-testing-performance-task-definition.json"
          family_name="assurance-testing-performance-task-definition"
          echo "$(jq --arg f "$family_name" '.family = $f' "${{ steps.create-task-definition.outputs.task-definition }}")" > "$file_path"
          task_definition_arn=$(aws ecs register-task-definition \
                                  --cli-input-json file://$file_path \
                                  --query 'taskDefinition.taskDefinitionArn' \
                                  --output text
                                )
          echo "task_definition_arn=$task_definition_arn" >> $GITHUB_OUTPUT
      - name: Start performance test
        id: run-task
        run: |
          echo "Starting ECS task to run performance test against ${{ inputs.URN }}"
          
          subnet_id=$(aws ec2 describe-subnets --filters Name=tag:Name,Values=assurance-testing-subnet --query 'Subnets[0].SubnetId' --output text)
          security_group_id=$(aws ec2 describe-security-groups --filters Name=group-name,Values=assurance-testing-performance-sg --query 'SecurityGroups[0].GroupId' --output text)
          
          task_arn=$(aws ecs run-task \
            --cluster assurance-testing \
            --task-definition ${{ steps.register-task-definition.outputs.task_definition_arn }} \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={subnets=[$subnet_id],securityGroups=[$security_group_id],assignPublicIp=ENABLED}" \
            --overrides '{
              "containerOverrides": [{
                "name": "performancetest-container"
              }]
            }' \
            --query 'tasks[0].taskArn' \
            --enable-execute-command \
            --output text)
          
          echo "task_arn=$task_arn" >> $GITHUB_OUTPUT
          echo "Started task: $task_arn"
      - name: Wait for performance test to complete
        run: |
          #TODO: Add link to cloudwatch here
          echo "Waiting for task to complete: ${{ steps.run-task.outputs.task_arn }}"          
          while true; do
            task_status=$(aws ecs describe-tasks \
              --cluster assurance-testing \
              --tasks ${{ steps.run-task.outputs.task_arn }} \
              --query 'tasks[0].lastStatus' \
              --output text)
            
            echo "Current task status: $task_status"
            if [ "$task_status" == "STOPPED" ]; then
              echo "Task has stopped"
              break
            fi
            sleep 30 # Check every 30 seconds
          done
          
          exit_code=$(aws ecs describe-tasks \
            --cluster assurance-testing \
            --tasks ${{ steps.run-task.outputs.task_arn }} \
            --query 'tasks[0].containers[0].exitCode' \
            --output text)
          
          echo "Container exit code: $exit_code"
          
          if [ "$exit_code" != "0" ]; then
            echo "ECS task failed with exit code: $exit_code"
            exit 1
          fi
      - name: Collect test result
        id: collect-results
        run: |
          echo "Downloading test results from S3"
          S3_PATH="s3://performancetest-reports/${{ env.RESULT_PATH }}"          
          aws s3 sync "${S3_PATH}" ./test-results --no-progress

      - name: Upload nurse journey JMeter output
        if: inputs.runNurse == true
        uses: actions/upload-artifact@v5
        with:
          name: jmeter-nurse-journey-output-${{ env.timestamp }}
          path: test-results/nurse
          if-no-files-found: warn
      - name: Upload consent journey JMeter output
        if: inputs.runConsent == true
        uses: actions/upload-artifact@v5
        with:
          name: jmeter-consent-journey-output-${{ env.timestamp }}
          path: test-results/consent
          if-no-files-found: warn
      - name: Publish report to GH Pages
        if: inputs.runNurse == true
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_branch: gh-pages
          publish_dir: test-results/nurse/report
          destination_dir: JMeter/${{ env.RESULT_PATH }}
          keep_files: true
      - name: Set Job Summary
        run: |
          echo "## Performance Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **URN:** ${{ inputs.URN }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Run Number:** ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“Š View Test Report: https://nhsdigital.github.io/manage-vaccinations-in-schools-testing/JMeter/${{ env.RESULT_PATH }}/" >> $GITHUB_STEP_SUMMARY
